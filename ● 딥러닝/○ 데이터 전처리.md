# 데이터 전처리

## 이미지
```
from sklearn.model_selection import train_test_split

# 데이터 분할(훈련 + 테스트) + 데이터 내부 불러오기
(xtrain_all, ytrain_all), (xtest, ytest) = keras.datasets.fashion_mnist.load_data()

# 데이터 스케일링(정규화)
xtrain_all_scaled = xtrain_all.reshape(-1, 너비, 높이, 깊이) / 255
xtest = xtest.reshape(-1, 너비, 높이, 깊이) / 255

# 데이터 분할(훈련 + 검증)
xtrain, xval, ytrain, yval = train_test_split(
 
    xtrain_all_scaled, ytrain_all    # x: 특성, y: 타겟
    , test_size = 0.25       # 검증 데이터 비율(0~1)
#   , stratify = target      # 훈련 데이터 클래스 비율 = 검증 데이터 클래스 비율
    )
    
print( xtrain.shape, xval.shape, xtest.shape )    # (훈련/검증/테스트 샘플 갯수, 너비, 높이, 깊이)
```

## 텍스트
```angular2html
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences


# 데이터 분할(훈련 + 테스트) + 데이터 내부 불러오기
(xtrain_all, ytrain_all), (xtest, ytest) = imdb.load_data(
    num_words = 어휘 사전 크기 )

# 데이터 분할(훈련 + 검증)
xtrain, xval, ytrain, yval = train_test_split(
 
    xtrain_all, ytrain_all    # x: 특성, y: 타겟
    , test_size = 0.25       # 검증 데이터 비율(0~1)
#   , stratify = target      # 훈련 데이터 클래스 비율 = 검증 데이터 클래스 비율
    )

# 패딩
xtrain_seq = pad_sequences(
    xtrain
    , maxlen = 토큰 지정 길이  
    , padding = 'pre'       # 패딩 위치(앞: pre, 뒤: post)
    , truncating = 'pre'    # 잘라내기 위치(앞: pre, 뒤: post)
    )

xval_seq = pad_sequences(
    xval
    , maxlen = 토큰 지정 길이     
    , padding = 'pre'       # 패딩 위치(앞: pre, 뒤: post)
    , truncating = 'pre'    # 잘라내기 위치(앞: pre, 뒤: post)
    )
```

